{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "import urllib\n",
    "import bs4\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function (1) `createDF`\n",
    "* Create DataFrame from Google News Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDF():\n",
    "\n",
    "    keyword_input = str(input('Please enter a keyword to search on Google News:'))\n",
    "    days_input = str(input('How many days ago do you want the articles to have been published?:'))\n",
    "\n",
    "    url = 'https://news.google.com/search' + \\\n",
    "        '?q=' + keyword_input + \\\n",
    "        '%20when%3A' + days_input + 'd' + \\\n",
    "        '&hl=ko-KR&gl=KR&ceid=US%3Aen'\n",
    "\n",
    "    res = requests.get(url)\n",
    "    soup = bs4.BeautifulSoup(res.text, 'lxml')\n",
    "    items = soup.select('article > div > div > div > a')\n",
    "\n",
    "    titles_list, links_list = [], []\n",
    "\n",
    "    for item in items:\n",
    "        title = item.text\n",
    "        link = 'https://news.google.com' + items[0].get('href')\n",
    "        titles_list.append(title)\n",
    "        links_list.append(link)\n",
    "\n",
    "    titles_links_dict = {\n",
    "        'title': titles_list,\n",
    "        'link': links_list\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(titles_links_dict)\n",
    "    return [df, keyword_input, days_input]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function (2) `createWordCloud`\n",
    "* Create WordCloud from the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createWordCloud([df, keyword_input, days_input]):\n",
    "\n",
    "    cv = CountVectorizer(\n",
    "        max_features = 1000,\n",
    "        stop_words = 'english'\n",
    "    )\n",
    "    tdm = cv.fit_transform(\n",
    "        df['title']\n",
    "    )\n",
    "    tfidf_trans = TfidfTransformer()\n",
    "    tdm_tfidf = tfidf_trans.fit_transform(tdm)    \n",
    "\n",
    "    words_freqs_df = pd.DataFrame(\n",
    "        {\n",
    "            'word': cv.get_feature_names_out(),\n",
    "            'frequency': tdm_tfidf.sum(axis=0).flat\n",
    "        }\n",
    "    )\n",
    "    words_freqs_df = words_freqs_df.sort_values('frequency', ascending=False).reset_index(drop=True)\n",
    "    words_freqs_dict = dict(\n",
    "        zip(\n",
    "            words_freqs_df['word'],\n",
    "            words_freqs_df['frequency']\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # (1) remove keyword itself from the dictionary.\n",
    "    if words_freqs_dict.get(keyword_input) != None:\n",
    "        del words_freqs_dict[keyword_input]\n",
    "    for word in keyword_input.split():\n",
    "        if words_freqs_dict.get(word) != None:\n",
    "            del words_freqs_dict[word]\n",
    "\n",
    "    # (2) remove '\\d\\d\\d\\d'(4 digits) (probably meaning the year such as 2021 and 2022)\n",
    "    deletes_list = []\n",
    "    for k in words_freqs_dict.keys():\n",
    "        pattern = r'\\d\\d\\d\\d'\n",
    "        repatter = re.compile(pattern)\n",
    "        match = repatter.match(k)\n",
    "        if match != None:\n",
    "            deletes_list.append(k)\n",
    "    if deletes_list != []:\n",
    "        for k in deletes_list:\n",
    "            del words_freqs_dict[k]\n",
    "\n",
    "    wc = WordCloud(\n",
    "        background_color = 'white',\n",
    "        max_words = 100,\n",
    "        height = 500,\n",
    "        width = 1000\n",
    "    )\n",
    "    cloud = wc.fit_words(words_freqs_dict)\n",
    "\n",
    "    # save wordcloud image\n",
    "    FOLDER_NAME = 'wordcloud'\n",
    "    today = datetime.today().strftime('%Y-%m-%d')\n",
    "    FILE_NAME = today + '_' + str(keyword_input) + '_' + str(days_input) + '.png'\n",
    "    FILE_PATH = FOLDER_NAME + '/' + FILE_NAME\n",
    "    if not os.path.exists(FOLDER_NAME):\n",
    "        os.makedirs(FOLDER_NAME)\n",
    "    cloud.to_file(FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module including:\n",
    "* Function (1) `createDF`\n",
    "* Function (2) `createWordCloud`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createWordCloud(createDF())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
